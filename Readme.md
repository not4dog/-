< 모델링 설명 >

요약 : 클러스터링을 통해 데이터를 두 개의 군집 ( 정상, Cerber )로 나눈 다음, 군집에 맞는 분류 모델을 각각 학습 시킨다.


0. 지도 학습과는 달리 정답 라벨이 없는 데이터를 앞에서 나온 특징들(Opcode,API)을 K-Means Clustering을 통해 실행파일에 대한 결과(정상,cerber)를 예측 할 수 있는 2개의 군집으로 만든다. 
( 지도 학습에서 적절한 피처를 찾아내기 위한 전처리 과정 )


1. 2개의 군집을 3개의 분류 모델 ( RF, SVM, NB )를 이용하여 학습 시킨다.

< 선정이유 >

NB : 대표적인 확률론적 분류 모델의 일종으로 각 특징(Feature)들 사이에 독립성을 가정으로 하는 베이즈 정리를 토대로 분류하는 알고리즘

< 특징 >

장점 : 학습 데이터 양의 적은 상황에서 좋은 성능 기대, 많은 특징들 사용 시 차원 저주 영향 X

단점 : 모든 특징들이 독립적으로 보기 때문에 특징 추출 시 종속 관계를 가지는 특징 조합, 상관관계에 대해서 좋은 결과 기대하기 힘듬

RF : 대표적인 앙상블 기반 알고리즘, 전체 데이터에서 무작위로 여러 갱의 하위 데이터를 추출 후, 여러 개 모델 생성 전체 데이터를 하나의 모델로 만드련 분류에 가장 도움이 되는 특징을 위주로 트리를 생성하는 분류 알고리즘


장점 : 학습 데이터에서 큰 비중이 없는 특징들을 새롭게 유입하는 데이터에서는 중요한 역할이 될 수 있는데 이런 부분들을 포착하기 쉬움

특징 중요도를 계산하여 분류에 가장 많이 도움이 되는 특징을 백분율로 계산 ( 특징 공학 시 좋은 특징 선정 시 기준으로 사용 )


SVM : 분류하려는 두 영역을 하나의 선으로 나눌 때, 선이 양쪽에 위치하는 점들과의 거리가 최대가 되도록 만드는 것이 목표


2. 정적 특징과 동적 특징을 합쳐서 악성코드 탐지 모델을 만든 후 최적의 학습 매개변수 값(RF,SVM)을 정하기 위해 Optuna라는 자동 하이퍼파라미터 최적화 software framework를 이용하여 모델의 성능을 올린다.












< 참고 >

출처: https://ebbnflow.tistory.com/165 [삶은 확률의 구름:티스토리]

Native API 빈도 기반의 퍼지 군집화를 이용한 악성코드 재그룹화 기법연구 : https://koreascience.kr/article/JAKO200805441029427.pdf

https://koreascience.kr/article/JAKO201919163609471.pdf 
